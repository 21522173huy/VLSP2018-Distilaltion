{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'student/checkpoints' already exists.\n",
      "Train Dataset: 3000\n",
      "Val Dataset: 2000\n",
      "Test Dataset: 600\n",
      "Sample Shape:  torch.Size([4, 256])\n",
      "trang_thiết_bị trong phòng_không tốt lắm tivi vẫn còn sử_dụng model đời cũ tiêu_chuẩn như 3 sao thì tv phải sử_dụng lcd nhân_viên tiếp_tân chưa tư_vấn cho khách nhiệt_tình về các dịch_vụ và khuyến_mại của khách_sạn\n",
      "Using device: cpu\n",
      "Train Only Classifier Layer\n",
      "Using device: cpu\n",
      "Train Only Classifier Layer\n",
      "Number of student model parameters: 1625424.0M\n",
      "Step: 0, Learning Rate Factor: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\main_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tuleh\\Desktop\\VLSP2018-Distillation\\student\\training_script.py\", line 135, in <module>\n",
      "    main()\n",
      "  File \"c:\\Users\\tuleh\\Desktop\\VLSP2018-Distillation\\student\\training_script.py\", line 109, in main\n",
      "    train_loss, test_loss, train_metrics, test_metrics = training_student(pred_distill=args.pred_distill,\n",
      "                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: training_student() missing 1 required positional argument: 'loss_type'\n"
     ]
    }
   ],
   "source": [
    "!python student/training_script.py --teacher_ver 2 --teacher_name vinai/phobert-large --teacher_checkpoint teacher/checkpoints/Hotel/PhobertLarge/Best.pt --num_student_layers 4 --data_path dataset/preprocessed_hotel --epochs 1 --batch_size 4 --soft_weight 0.5 --hard_weight 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
